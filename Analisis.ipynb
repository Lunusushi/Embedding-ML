{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "target=[]\n",
    "edad=[]\n",
    "sexo=[]\n",
    "severidad=[]\n",
    "archivo=open(\"datasets/dataset_elpino.csv\",encoding=\"utf-8\") #pon aqui la ruta de tu dataset siendo el root donde se encuentra este codigo\n",
    "header=archivo.readline().strip().split(\";\")\n",
    "features=[]\n",
    "for col in header:\n",
    "    col=col.split(\"-\")[0].strip()\n",
    "    if col.startswith(\"Diag\") or col.startswith(\"Proc\"):\n",
    "        col=col.split(\" \")\n",
    "        col=col[0]+col[1]\n",
    "    features.append(col)\n",
    "for linea in archivo:\n",
    "    row=[]\n",
    "    linea=linea.strip().split(\";\")\n",
    "    for i in range(len(linea)):\n",
    "        col=linea[i].split(\"-\")[0].strip()\n",
    "        if i==67:\n",
    "            grd=col\n",
    "            #target.append(grd[-1])\n",
    "            target.append(grd)\n",
    "        elif i==66:\n",
    "            sexo.append(1 if col==\"Mujer\" else 0)\n",
    "        elif i==65:\n",
    "            edad.append(int(col))\n",
    "        else:\n",
    "            row.append(col)\n",
    "    corpus.append(row)\n",
    "\n",
    "archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(corpus,columns=features[:-3])\n",
    "df[\"GRD\"]=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Junta todas las columnas de codigos en una sola lista\n",
    "code_columns = [col for col in df.columns if col.startswith(\"Diag\") or col.startswith(\"Proc\")]\n",
    "\n",
    "#Aplanar los codigos para construir el vocabulario\n",
    "all_codes = df[code_columns].values.flatten()\n",
    "unique_codes = pd.Series(all_codes).dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion del vocabulario\n",
    "lookup_layer = tf.keras.layers.StringLookup(vocabulary=unique_codes, oov_token=\"[UNK]\")\n",
    "\n",
    "#Codigos a tensores de string y aplica StringLookup\n",
    "X_codes_str = tf.constant(df[code_columns].astype(str).values)\n",
    "X_codes_idx = lookup_layer(X_codes_str)\n",
    "\n",
    "#Padding\n",
    "X_padded = pad_sequences(X_codes_idx.numpy(), padding='post')\n",
    "\n",
    "#Codifica los GRD como enteros\n",
    "grd_lookup = tf.keras.layers.StringLookup(oov_token=\"[UNK]\")\n",
    "grd_lookup.adapt(df[\"GRD\"])\n",
    "y = grd_lookup(df[\"GRD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y.numpy(), test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "#Define modelo en Keras\n",
    "vocab_size = lookup_layer.vocabulary_size()\n",
    "num_classes = grd_lookup.vocabulary_size()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=64),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.0453 - loss: 5.6137 - val_accuracy: 0.0529 - val_loss: 5.1565\n",
      "Epoch 2/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.0670 - loss: 5.0094 - val_accuracy: 0.0932 - val_loss: 4.6855\n",
      "Epoch 3/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.1078 - loss: 4.4652 - val_accuracy: 0.1291 - val_loss: 4.2605\n",
      "Epoch 4/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.1341 - loss: 4.0516 - val_accuracy: 0.1215 - val_loss: 4.0778\n",
      "Epoch 5/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.1342 - loss: 3.9293 - val_accuracy: 0.1552 - val_loss: 3.9271\n",
      "Epoch 6/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.1585 - loss: 3.6825 - val_accuracy: 0.1598 - val_loss: 3.7736\n",
      "Epoch 7/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.1797 - loss: 3.4688 - val_accuracy: 0.1767 - val_loss: 3.6161\n",
      "Epoch 8/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2074 - loss: 3.2536 - val_accuracy: 0.2197 - val_loss: 3.4913\n",
      "Epoch 9/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2539 - loss: 3.0567 - val_accuracy: 0.2412 - val_loss: 3.4105\n",
      "Epoch 10/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2741 - loss: 2.8888 - val_accuracy: 0.2703 - val_loss: 3.2744\n",
      "Epoch 11/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.3079 - loss: 2.7042 - val_accuracy: 0.2824 - val_loss: 3.2468\n",
      "Epoch 12/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.3501 - loss: 2.5184 - val_accuracy: 0.3271 - val_loss: 3.1254\n",
      "Epoch 13/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.3848 - loss: 2.3511 - val_accuracy: 0.3822 - val_loss: 2.9823\n",
      "Epoch 14/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.4871 - loss: 2.0053 - val_accuracy: 0.4477 - val_loss: 2.8054\n",
      "Epoch 15/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5211 - loss: 1.8233 - val_accuracy: 0.4651 - val_loss: 2.7580\n",
      "Epoch 16/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.5714 - loss: 1.6519 - val_accuracy: 0.4788 - val_loss: 2.7379\n",
      "Epoch 17/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6021 - loss: 1.4975 - val_accuracy: 0.5093 - val_loss: 2.6930\n",
      "Epoch 18/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6203 - loss: 1.4199 - val_accuracy: 0.5175 - val_loss: 2.7279\n",
      "Epoch 19/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6664 - loss: 1.2456 - val_accuracy: 0.5404 - val_loss: 2.6977\n",
      "Epoch 20/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6776 - loss: 1.1730 - val_accuracy: 0.5379 - val_loss: 2.7064\n",
      "Epoch 21/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.6941 - loss: 1.0902 - val_accuracy: 0.5608 - val_loss: 2.6532\n",
      "Epoch 22/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7192 - loss: 0.9902 - val_accuracy: 0.5708 - val_loss: 2.7182\n",
      "Epoch 23/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7513 - loss: 0.8689 - val_accuracy: 0.5933 - val_loss: 2.7258\n",
      "Epoch 24/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7785 - loss: 0.8053 - val_accuracy: 0.6081 - val_loss: 2.7487\n",
      "Epoch 25/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8077 - loss: 0.7241 - val_accuracy: 0.6203 - val_loss: 2.7727\n",
      "Epoch 26/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8217 - loss: 0.6507 - val_accuracy: 0.6162 - val_loss: 2.7633\n",
      "Epoch 27/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8252 - loss: 0.6224 - val_accuracy: 0.6333 - val_loss: 2.7879\n",
      "Epoch 28/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8476 - loss: 0.5525 - val_accuracy: 0.6299 - val_loss: 2.9037\n",
      "Epoch 29/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8713 - loss: 0.4808 - val_accuracy: 0.6397 - val_loss: 2.9346\n",
      "Epoch 30/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8757 - loss: 0.4435 - val_accuracy: 0.6368 - val_loss: 3.0326\n",
      "Epoch 31/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8825 - loss: 0.4336 - val_accuracy: 0.6461 - val_loss: 3.0372\n",
      "Epoch 32/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8898 - loss: 0.4103 - val_accuracy: 0.6503 - val_loss: 3.0202\n",
      "Epoch 33/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9086 - loss: 0.3391 - val_accuracy: 0.6537 - val_loss: 3.0896\n",
      "Epoch 34/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9141 - loss: 0.3270 - val_accuracy: 0.6564 - val_loss: 3.0950\n",
      "Epoch 35/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9070 - loss: 0.3345 - val_accuracy: 0.6649 - val_loss: 3.0902\n",
      "Epoch 36/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9243 - loss: 0.2807 - val_accuracy: 0.6683 - val_loss: 3.2397\n",
      "Epoch 37/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9312 - loss: 0.2615 - val_accuracy: 0.6523 - val_loss: 3.3289\n",
      "Epoch 38/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9299 - loss: 0.2491 - val_accuracy: 0.6629 - val_loss: 3.3404\n",
      "Epoch 39/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9350 - loss: 0.2289 - val_accuracy: 0.6709 - val_loss: 3.3382\n",
      "Epoch 40/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9517 - loss: 0.1870 - val_accuracy: 0.6670 - val_loss: 3.3948\n",
      "Epoch 41/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9564 - loss: 0.1728 - val_accuracy: 0.6706 - val_loss: 3.4549\n",
      "Epoch 42/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9512 - loss: 0.1796 - val_accuracy: 0.6683 - val_loss: 3.4981\n",
      "Epoch 43/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9487 - loss: 0.1790 - val_accuracy: 0.6622 - val_loss: 3.6029\n",
      "Epoch 44/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9559 - loss: 0.1688 - val_accuracy: 0.6743 - val_loss: 3.5243\n",
      "Epoch 45/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9615 - loss: 0.1547 - val_accuracy: 0.6789 - val_loss: 3.5791\n",
      "Epoch 46/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9740 - loss: 0.1129 - val_accuracy: 0.6754 - val_loss: 3.6427\n",
      "Epoch 47/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9752 - loss: 0.1026 - val_accuracy: 0.6718 - val_loss: 3.7963\n",
      "Epoch 48/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9780 - loss: 0.0992 - val_accuracy: 0.6775 - val_loss: 3.7837\n",
      "Epoch 49/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9796 - loss: 0.0938 - val_accuracy: 0.6690 - val_loss: 3.8133\n",
      "Epoch 50/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9684 - loss: 0.1238 - val_accuracy: 0.6766 - val_loss: 3.8788\n",
      "Epoch 51/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9606 - loss: 0.1472 - val_accuracy: 0.6784 - val_loss: 3.8138\n",
      "Epoch 52/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9712 - loss: 0.1077 - val_accuracy: 0.6825 - val_loss: 3.8447\n",
      "Epoch 53/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9720 - loss: 0.1081 - val_accuracy: 0.6754 - val_loss: 3.9088\n",
      "Epoch 54/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9797 - loss: 0.0789 - val_accuracy: 0.6926 - val_loss: 3.9032\n",
      "Epoch 55/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9842 - loss: 0.0661 - val_accuracy: 0.6812 - val_loss: 4.0285\n",
      "Epoch 56/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9817 - loss: 0.0822 - val_accuracy: 0.6759 - val_loss: 4.0030\n",
      "Epoch 57/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9724 - loss: 0.1023 - val_accuracy: 0.6825 - val_loss: 4.0029\n",
      "Epoch 58/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9857 - loss: 0.0603 - val_accuracy: 0.6887 - val_loss: 4.0103\n",
      "Epoch 59/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9909 - loss: 0.0448 - val_accuracy: 0.6878 - val_loss: 4.1093\n",
      "Epoch 60/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9900 - loss: 0.0444 - val_accuracy: 0.6818 - val_loss: 4.1618\n",
      "Epoch 61/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9783 - loss: 0.0889 - val_accuracy: 0.6784 - val_loss: 4.0711\n",
      "Epoch 62/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9819 - loss: 0.0695 - val_accuracy: 0.6887 - val_loss: 4.1284\n",
      "Epoch 63/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9870 - loss: 0.0503 - val_accuracy: 0.6816 - val_loss: 4.1826\n",
      "Epoch 64/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9822 - loss: 0.0651 - val_accuracy: 0.6791 - val_loss: 4.2567\n",
      "Epoch 65/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9833 - loss: 0.0632 - val_accuracy: 0.6910 - val_loss: 4.1764\n",
      "Epoch 66/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9820 - loss: 0.0649 - val_accuracy: 0.6812 - val_loss: 4.2343\n",
      "Epoch 67/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9612 - loss: 0.1418 - val_accuracy: 0.6935 - val_loss: 4.2346\n",
      "Epoch 68/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9841 - loss: 0.0672 - val_accuracy: 0.6921 - val_loss: 4.1404\n",
      "Epoch 69/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9880 - loss: 0.0454 - val_accuracy: 0.6940 - val_loss: 4.1451\n",
      "Epoch 70/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9927 - loss: 0.0343 - val_accuracy: 0.7002 - val_loss: 4.2354\n",
      "Epoch 71/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9932 - loss: 0.0278 - val_accuracy: 0.6912 - val_loss: 4.2422\n",
      "Epoch 72/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9931 - loss: 0.0260 - val_accuracy: 0.6986 - val_loss: 4.2291\n",
      "Epoch 73/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9946 - loss: 0.0224 - val_accuracy: 0.6992 - val_loss: 4.2765\n",
      "Epoch 74/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9942 - loss: 0.0231 - val_accuracy: 0.7018 - val_loss: 4.2680\n",
      "Epoch 75/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9963 - loss: 0.0162 - val_accuracy: 0.7022 - val_loss: 4.3332\n",
      "Epoch 76/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9942 - loss: 0.0191 - val_accuracy: 0.7015 - val_loss: 4.3630\n",
      "Epoch 77/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9961 - loss: 0.0167 - val_accuracy: 0.7052 - val_loss: 4.3876\n",
      "Epoch 78/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9967 - loss: 0.0151 - val_accuracy: 0.6999 - val_loss: 4.4293\n",
      "Epoch 79/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9679 - loss: 0.1193 - val_accuracy: 0.6665 - val_loss: 4.4777\n",
      "Epoch 80/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9498 - loss: 0.1692 - val_accuracy: 0.6757 - val_loss: 4.1822\n",
      "Epoch 81/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9686 - loss: 0.1047 - val_accuracy: 0.6880 - val_loss: 4.0478\n",
      "Epoch 82/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9872 - loss: 0.0458 - val_accuracy: 0.7002 - val_loss: 4.0744\n",
      "Epoch 83/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9953 - loss: 0.0239 - val_accuracy: 0.7050 - val_loss: 4.1508\n",
      "Epoch 84/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9959 - loss: 0.0174 - val_accuracy: 0.7089 - val_loss: 4.1336\n",
      "Epoch 85/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9956 - loss: 0.0144 - val_accuracy: 0.7082 - val_loss: 4.1968\n",
      "Epoch 86/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9966 - loss: 0.0126 - val_accuracy: 0.7063 - val_loss: 4.2093\n",
      "Epoch 87/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9959 - loss: 0.0134 - val_accuracy: 0.7059 - val_loss: 4.2255\n",
      "Epoch 88/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9974 - loss: 0.0111 - val_accuracy: 0.7036 - val_loss: 4.3154\n",
      "Epoch 89/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9969 - loss: 0.0124 - val_accuracy: 0.7052 - val_loss: 4.3419\n",
      "Epoch 90/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9955 - loss: 0.0154 - val_accuracy: 0.7075 - val_loss: 4.3137\n",
      "Epoch 91/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9973 - loss: 0.0115 - val_accuracy: 0.7068 - val_loss: 4.3713\n",
      "Epoch 92/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9981 - loss: 0.0106 - val_accuracy: 0.7066 - val_loss: 4.4156\n",
      "Epoch 93/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9971 - loss: 0.0113 - val_accuracy: 0.6999 - val_loss: 4.5234\n",
      "Epoch 94/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9832 - loss: 0.0614 - val_accuracy: 0.6681 - val_loss: 4.4369\n",
      "Epoch 95/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9448 - loss: 0.1794 - val_accuracy: 0.7027 - val_loss: 4.1196\n",
      "Epoch 96/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9822 - loss: 0.0642 - val_accuracy: 0.7043 - val_loss: 4.0548\n",
      "Epoch 97/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9897 - loss: 0.0423 - val_accuracy: 0.7011 - val_loss: 4.1183\n",
      "Epoch 98/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9965 - loss: 0.0174 - val_accuracy: 0.7116 - val_loss: 4.1452\n",
      "Epoch 99/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9972 - loss: 0.0134 - val_accuracy: 0.7107 - val_loss: 4.1866\n",
      "Epoch 100/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9962 - loss: 0.0137 - val_accuracy: 0.7160 - val_loss: 4.1869\n",
      "Epoch 101/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9975 - loss: 0.0104 - val_accuracy: 0.7162 - val_loss: 4.2360\n",
      "Epoch 102/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9963 - loss: 0.0133 - val_accuracy: 0.7123 - val_loss: 4.2712\n",
      "Epoch 103/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9957 - loss: 0.0133 - val_accuracy: 0.7171 - val_loss: 4.2882\n",
      "Epoch 104/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9960 - loss: 0.0165 - val_accuracy: 0.7093 - val_loss: 4.3404\n",
      "Epoch 105/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9941 - loss: 0.0198 - val_accuracy: 0.7116 - val_loss: 4.3453\n",
      "Epoch 106/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9960 - loss: 0.0140 - val_accuracy: 0.7082 - val_loss: 4.3328\n",
      "Epoch 107/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9973 - loss: 0.0110 - val_accuracy: 0.7109 - val_loss: 4.3755\n",
      "Epoch 108/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9965 - loss: 0.0117 - val_accuracy: 0.7121 - val_loss: 4.4409\n",
      "Epoch 109/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9969 - loss: 0.0105 - val_accuracy: 0.7109 - val_loss: 4.4118\n",
      "Epoch 110/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9884 - loss: 0.0393 - val_accuracy: 0.6809 - val_loss: 4.4294\n",
      "Epoch 111/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9599 - loss: 0.1357 - val_accuracy: 0.6896 - val_loss: 4.2067\n",
      "Epoch 112/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9756 - loss: 0.0771 - val_accuracy: 0.7022 - val_loss: 4.1787\n",
      "Epoch 113/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9896 - loss: 0.0390 - val_accuracy: 0.7047 - val_loss: 4.2119\n",
      "Epoch 114/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9931 - loss: 0.0267 - val_accuracy: 0.7166 - val_loss: 4.1553\n",
      "Epoch 115/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9962 - loss: 0.0135 - val_accuracy: 0.7185 - val_loss: 4.1906\n",
      "Epoch 116/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9964 - loss: 0.0144 - val_accuracy: 0.7160 - val_loss: 4.2323\n",
      "Epoch 117/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9964 - loss: 0.0105 - val_accuracy: 0.7148 - val_loss: 4.2549\n",
      "Epoch 118/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9968 - loss: 0.0116 - val_accuracy: 0.7164 - val_loss: 4.2810\n",
      "Epoch 119/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9978 - loss: 0.0088 - val_accuracy: 0.7176 - val_loss: 4.2911\n",
      "Epoch 120/120\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9975 - loss: 0.0100 - val_accuracy: 0.7162 - val_loss: 4.3019\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7167 - loss: 4.4280\n",
      "Accuracy en test: 71.62%\n"
     ]
    }
   ],
   "source": [
    "#Entrenar modelo\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=120, batch_size=64)\n",
    "\n",
    "#Evaluar modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Accuracy en test: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guarda el modelo\n",
    "model.save(\"modelo_general.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "# Convierte predicciones a labels de clase discreta\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Clase con mayor probabilidad\n",
    "\n",
    "#clasificacion\n",
    "print(f\"Reporte clasificacion:\\n{classification_report(y_test, y_pred_classes)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
